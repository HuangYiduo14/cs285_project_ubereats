{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run_hw3_dqn.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gUl_qfOR8JV6"},"source":["##Setup\n","\n","You will need to make a copy of this notebook in your Google Drive before you can edit the homework files. You can do so with **File &rarr; Save a copy in Drive**."]},{"cell_type":"code","metadata":{"id":"iizPcHAp8LnA","cellView":"form","executionInfo":{"status":"ok","timestamp":1602178385787,"user_tz":420,"elapsed":21849,"user":{"displayName":"Yiduo Huang","photoUrl":"","userId":"07549364584604969970"}},"outputId":"a8af7bba-aded-4afc-e45a-6c649bda1940","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["#@title mount your Google Drive\n","#@markdown Your work will be stored in a folder called `cs285_f2020` by default to prevent Colab instance timeouts from deleting your edits.\n","\n","import os\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nAb10wnb8N0m","cellView":"form"},"source":["#@title set up mount symlink\n","\n","DRIVE_PATH = '/content/gdrive/My\\ Drive/cs285_f2020'\n","DRIVE_PYTHON_PATH = DRIVE_PATH.replace('\\\\', '')\n","if not os.path.exists(DRIVE_PYTHON_PATH):\n","  %mkdir $DRIVE_PATH\n","\n","## the space in `My Drive` causes some issues,\n","## make a symlink to avoid this\n","SYM_PATH = '/content/cs285_f2020'\n","if not os.path.exists(SYM_PATH):\n","  !ln -s $DRIVE_PATH $SYM_PATH"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gtS9-WsD8QVr","cellView":"form","executionInfo":{"status":"ok","timestamp":1602178428721,"user_tz":420,"elapsed":64745,"user":{"displayName":"Yiduo Huang","photoUrl":"","userId":"07549364584604969970"}},"outputId":"a479c54d-40f8-4f05-bd60-5fac10e8f7e6","colab":{"base_uri":"https://localhost:8080/","height":631}},"source":["#@title apt install requirements\n","\n","#@markdown Run each section with Shift+Enter\n","\n","#@markdown Double-click on section headers to show code.\n","\n","!apt update \n","!apt install -y --no-install-recommends \\\n","        build-essential \\\n","        curl \\\n","        git \\\n","        gnupg2 \\\n","        make \\\n","        cmake \\\n","        ffmpeg \\\n","        swig \\\n","        libz-dev \\\n","        unzip \\\n","        zlib1g-dev \\\n","        libglfw3 \\\n","        libglfw3-dev \\\n","        libxrandr2 \\\n","        libxinerama-dev \\\n","        libxi6 \\\n","        libxcursor-dev \\\n","        libgl1-mesa-dev \\\n","        libgl1-mesa-glx \\\n","        libglew-dev \\\n","        libosmesa6-dev \\\n","        lsb-release \\\n","        ack-grep \\\n","        patchelf \\\n","        wget \\\n","        xpra \\\n","        xserver-xorg-dev \\\n","        xvfb \\\n","        python-opengl \\\n","        ffmpeg > /dev/null 2>&1\n","\n","!pip install opencv-python==3.4.0.12"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to security.u\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to security.u\u001b[0m\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to security.u\u001b[0m\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\u001b[0m\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\u001b[0m\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,675 kB]\n","Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,693 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,111 kB]\n","Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,341 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,104 kB]\n","Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [857 kB]\n","Fetched 10.1 MB in 3s (2,899 kB/s)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","8 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","Collecting opencv-python==3.4.0.12\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/f9/5c454f0f52788a913979877e6ed9b2454a9c7676581a0ee3a2d81db784a6/opencv_python-3.4.0.12-cp36-cp36m-manylinux1_x86_64.whl (24.9MB)\n","\u001b[K     |████████████████████████████████| 24.9MB 129kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python==3.4.0.12) (1.18.5)\n","\u001b[31mERROR: dopamine-rl 1.0.5 has requirement opencv-python>=3.4.1.15, but you'll have opencv-python 3.4.0.12 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: opencv-python\n","  Found existing installation: opencv-python 4.1.2.30\n","    Uninstalling opencv-python-4.1.2.30:\n","      Successfully uninstalled opencv-python-4.1.2.30\n","Successfully installed opencv-python-3.4.0.12\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VcKGekJN80NO","cellView":"form","executionInfo":{"status":"ok","timestamp":1602178428723,"user_tz":420,"elapsed":64727,"user":{"displayName":"Yiduo Huang","photoUrl":"","userId":"07549364584604969970"}},"outputId":"ba1b91fd-4377-448e-8f7e-0267d6c372b8","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["#@title download mujoco\n","\n","MJC_PATH = '{}/mujoco'.format(SYM_PATH)\n","if not os.path.exists(MJC_PATH):\n","  %mkdir $MJC_PATH\n","%cd $MJC_PATH\n","if not os.path.exists(os.path.join(MJC_PATH, 'mujoco200')):\n","  !wget -q https://www.roboti.us/download/mujoco200_linux.zip\n","  !unzip -q mujoco200_linux.zip\n","  %mv mujoco200_linux mujoco200\n","  %rm mujoco200_linux.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/cs285_f2020/mujoco\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NTiH9f9y82F_","cellView":"form"},"source":["#@title update mujoco paths\n","\n","import os\n","\n","os.environ['LD_LIBRARY_PATH'] += ':{}/mujoco200/bin'.format(MJC_PATH)\n","os.environ['MUJOCO_PY_MUJOCO_PATH'] = '{}/mujoco200'.format(MJC_PATH)\n","os.environ['MUJOCO_PY_MJKEY_PATH'] = '{}/mjkey.txt'.format(MJC_PATH)\n","\n","## installation on colab does not find *.so files\n","## in LD_LIBRARY_PATH, copy over manually instead\n","!cp $MJC_PATH/mujoco200/bin/*.so /usr/lib/x86_64-linux-gnu/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A0kPh99l87q0"},"source":["Ensure your `mjkey.txt` is in /content/cs285_f2020/mujoco before this step"]},{"cell_type":"code","metadata":{"id":"X-LoOdZg84pI","cellView":"form","executionInfo":{"status":"ok","timestamp":1602178472989,"user_tz":420,"elapsed":108973,"user":{"displayName":"Yiduo Huang","photoUrl":"","userId":"07549364584604969970"}},"outputId":"40092205-4a3a-430b-85ff-246ed61bb14f","colab":{"base_uri":"https://localhost:8080/","height":487}},"source":["#@title clone and install mujoco-py\n","\n","%cd $MJC_PATH\n","if not os.path.exists('mujoco-py'):\n","  !git clone https://github.com/openai/mujoco-py.git\n","%cd mujoco-py\n","%pip install -e .\n","\n","## cythonize at the first import\n","import mujoco_py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/cs285_f2020/mujoco\n","/content/gdrive/My Drive/cs285_f2020/mujoco/mujoco-py\n","Obtaining file:///content/gdrive/My%20Drive/cs285_f2020/mujoco/mujoco-py\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","\u001b[33m  WARNING: Missing build requirements in pyproject.toml for file:///content/gdrive/My%20Drive/cs285_f2020/mujoco/mujoco-py.\u001b[0m\n","\u001b[33m  WARNING: The project does not specify a build backend, and pip cannot fall back to setuptools without 'wheel'.\u001b[0m\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting fasteners~=0.15\n","  Using cached https://files.pythonhosted.org/packages/18/bd/55eb2d6397b9c0e263af9d091ebdb756b15756029b3cededf6461481bc63/fasteners-0.15-py2.py3-none-any.whl\n","Requirement already satisfied: Cython>=0.27.2 in /usr/local/lib/python3.6/dist-packages (from mujoco-py==2.0.2.13) (0.29.21)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from mujoco-py==2.0.2.13) (1.18.5)\n","Collecting glfw>=1.4.0\n","  Using cached https://files.pythonhosted.org/packages/12/72/3190b7cc8494c05d7fb350237d3f51abdaff79e74d1e13d6f84df4b57f6b/glfw-2.0.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl\n","Requirement already satisfied: cffi>=1.10 in /usr/local/lib/python3.6/dist-packages (from mujoco-py==2.0.2.13) (1.14.3)\n","Requirement already satisfied: imageio>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from mujoco-py==2.0.2.13) (2.4.1)\n","Collecting monotonic>=0.1\n","  Using cached https://files.pythonhosted.org/packages/ac/aa/063eca6a416f397bd99552c534c6d11d57f58f2e94c14780f3bbf818c4cf/monotonic-1.5-py2.py3-none-any.whl\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fasteners~=0.15->mujoco-py==2.0.2.13) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.10->mujoco-py==2.0.2.13) (2.20)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio>=2.1.2->mujoco-py==2.0.2.13) (7.0.0)\n","Installing collected packages: monotonic, fasteners, glfw, mujoco-py\n","  Running setup.py develop for mujoco-py\n","Successfully installed fasteners-0.15 glfw-2.0.0 monotonic-1.5 mujoco-py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-XcwBiBN8-Fg","cellView":"form","executionInfo":{"status":"ok","timestamp":1602178630654,"user_tz":420,"elapsed":266620,"user":{"displayName":"Yiduo Huang","photoUrl":"","userId":"07549364584604969970"}},"outputId":"39866add-932b-4baf-d25a-17d91f1e48c2","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#@title clone homework repo\n","#@markdown Note that this is the same codebase from homework 1,\n","#@markdown so you may need to move your old `homework_fall2020`\n","#@markdown folder in order to clone the repo again.\n","\n","#@markdown **Don't delete your old work though!**\n","#@markdown You will need it for this assignment.\n","\n","%cd $SYM_PATH\n","!git clone https://github.com/berkeleydeeprlcourse/homework_fall2020.git\n","\n","%cd homework_fall2020/hw3\n","%pip install -r requirements_colab.txt -f https://download.pytorch.org/whl/torch_stable.html\n","%pip install -e ."],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/cs285_f2020\n","fatal: destination path 'homework_fall2020' already exists and is not an empty directory.\n","/content/gdrive/My Drive/cs285_f2020/homework_fall2020/hw3\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Requirement already satisfied: gym[atari]==0.17.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements_colab.txt (line 1)) (0.17.2)\n","Requirement already satisfied: tensorboard==2.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements_colab.txt (line 2)) (2.3.0)\n","Collecting tensorboardX==1.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/12/dcaf67e1312475b26db9e45e7bb6f32b540671a9ee120b3a72d9e09bc517/tensorboardX-1.8-py2.py3-none-any.whl (216kB)\n","\u001b[K     |████████████████████████████████| 225kB 5.5MB/s \n","\u001b[?25hCollecting matplotlib==2.2.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/b8/89dbd27f2fb171ce753bb56220d4d4f6dbc5fe32b95d8edc4415782ef07f/matplotlib-2.2.2-cp36-cp36m-manylinux1_x86_64.whl (12.6MB)\n","\u001b[K     |████████████████████████████████| 12.6MB 240kB/s \n","\u001b[?25hCollecting ipython==6.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/7f/91d50f28af3e3a24342561983a7857e399ce24093876e6970b986a0b6677/ipython-6.4.0-py3-none-any.whl (750kB)\n","\u001b[K     |████████████████████████████████| 757kB 44.9MB/s \n","\u001b[?25hCollecting moviepy==1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/32/a93f4af8b88985304a748ca0a66a64eb9fac53d0a9355ec33e713c4a3bf5/moviepy-1.0.0.tar.gz (398kB)\n","\u001b[K     |████████████████████████████████| 399kB 55.2MB/s \n","\u001b[?25hCollecting pyvirtualdisplay==1.3.2\n","  Downloading https://files.pythonhosted.org/packages/d0/8a/643043cc70791367bee2d19eb20e00ed1a246ac48e5dbe57bbbcc8be40a9/PyVirtualDisplay-1.3.2-py2.py3-none-any.whl\n","Collecting torch==1.5.1\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torch-1.5.1%2Bcu92-cp36-cp36m-linux_x86_64.whl (604.8MB)\n","\u001b[K     |████████████████████████████████| 604.8MB 29kB/s \n","\u001b[?25hCollecting opencv-python==4.4.0.42\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/16/e49e5abd27d988e687634f58b0aa329fe737b686101cda48cd878f77429d/opencv_python-4.4.0.42-cp36-cp36m-manylinux2014_x86_64.whl (49.4MB)\n","\u001b[K     |████████████████████████████████| 49.4MB 59kB/s \n","\u001b[?25hCollecting ipdb==0.13.3\n","  Downloading https://files.pythonhosted.org/packages/c1/4c/c2552dc5c2f3a4657ae84c1a91e3c7d4f2b7df88a38d6d282e48d050ad58/ipdb-0.13.3.tar.gz\n","Collecting box2d-py\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/bd/6cdc3fd994b0649dcf5d9bad85bd9e26172308bbe9a421bfc6fdbf5081a6/box2d_py-2.3.8-cp36-cp36m-manylinux1_x86_64.whl (448kB)\n","\u001b[K     |████████████████████████████████| 450kB 48.5MB/s \n","\u001b[?25hRequirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]==0.17.2->-r requirements_colab.txt (line 1)) (1.3.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym[atari]==0.17.2->-r requirements_colab.txt (line 1)) (1.4.1)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]==0.17.2->-r requirements_colab.txt (line 1)) (1.5.0)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[atari]==0.17.2->-r requirements_colab.txt (line 1)) (1.18.5)\n","Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]==0.17.2->-r requirements_colab.txt (line 1)) (7.0.0)\n","Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]==0.17.2->-r requirements_colab.txt (line 1)) (0.2.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (0.4.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (2.23.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (1.15.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (1.7.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (3.2.2)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (0.10.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (0.35.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (50.3.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (1.32.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (3.12.4)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (1.17.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.2->-r requirements_colab.txt (line 4)) (1.2.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.2->-r requirements_colab.txt (line 4)) (2018.9)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.2->-r requirements_colab.txt (line 4)) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.2->-r requirements_colab.txt (line 4)) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.2->-r requirements_colab.txt (line 4)) (0.10.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython==6.4.0->-r requirements_colab.txt (line 5)) (4.4.2)\n","Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/dist-packages (from ipython==6.4.0->-r requirements_colab.txt (line 5)) (0.17.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from ipython==6.4.0->-r requirements_colab.txt (line 5)) (0.2.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython==6.4.0->-r requirements_colab.txt (line 5)) (0.7.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython==6.4.0->-r requirements_colab.txt (line 5)) (0.8.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython==6.4.0->-r requirements_colab.txt (line 5)) (4.3.3)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython==6.4.0->-r requirements_colab.txt (line 5)) (4.8.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.15 in /usr/local/lib/python3.6/dist-packages (from ipython==6.4.0->-r requirements_colab.txt (line 5)) (1.0.18)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython==6.4.0->-r requirements_colab.txt (line 5)) (2.6.1)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.6/dist-packages (from moviepy==1.0.0->-r requirements_colab.txt (line 6)) (4.41.1)\n","Collecting proglog<=1.0.0\n","  Downloading https://files.pythonhosted.org/packages/fe/ab/4cb19b578e1364c0b2d6efd6521a8b4b4e5c4ae6528041d31a2a951dd991/proglog-0.1.9.tar.gz\n","Collecting imageio<3.0,>=2.5\n","  Using cached https://files.pythonhosted.org/packages/6e/57/5d899fae74c1752f52869b613a8210a2480e1a69688e65df6cb26117d45d/imageio-2.9.0-py3-none-any.whl\n","Collecting imageio_ffmpeg>=0.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/c8/04c6b4a001b8ae7326fb83d6665af1ee58d6cc1acb421f8ea40d2678fe3c/imageio_ffmpeg-0.4.2-py3-none-manylinux2010_x86_64.whl (26.9MB)\n","\u001b[K     |████████████████████████████████| 26.9MB 112kB/s \n","\u001b[?25hCollecting EasyProcess\n","  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1->-r requirements_colab.txt (line 8)) (0.16.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (1.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (1.24.3)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (2.0.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (4.1.1)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (0.2.8)\n","Requirement already satisfied: parso<0.8.0,>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from jedi>=0.10->ipython==6.4.0->-r requirements_colab.txt (line 5)) (0.7.1)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython==6.4.0->-r requirements_colab.txt (line 5)) (0.2.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython==6.4.0->-r requirements_colab.txt (line 5)) (0.6.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.15->ipython==6.4.0->-r requirements_colab.txt (line 5)) (0.2.5)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (3.2.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard==2.3.0->-r requirements_colab.txt (line 2)) (0.4.8)\n","Building wheels for collected packages: moviepy, ipdb, proglog\n","  Building wheel for moviepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for moviepy: filename=moviepy-1.0.0-cp36-none-any.whl size=131366 sha256=4090fae503e17143504567ae4f874eee26b1ebe1b69c5d504eea185a53877bd1\n","  Stored in directory: /root/.cache/pip/wheels/52/e2/4c/f594a5945bc98e052ef248b46a0f1f7ea838b0b2a5f8895651\n","  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ipdb: filename=ipdb-0.13.3-cp36-none-any.whl size=10847 sha256=605b31c8aee024a0abecd8d96bebce67877523de2e13819cad5c36ee2018b571\n","  Stored in directory: /root/.cache/pip/wheels/75/00/30/4169bcc3643f0cf946dcf37af1b71364b390c4df91da02b03c\n","  Building wheel for proglog (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for proglog: filename=proglog-0.1.9-cp36-none-any.whl size=6149 sha256=57dede16bd5e6799cea4a9a8fe41dfa604d484907d88b00363adaf2486a2c3ff\n","  Stored in directory: /root/.cache/pip/wheels/65/56/60/1d0306a8d90b188af393c1812ddb502a8821b70917f82dcc00\n","Successfully built moviepy ipdb proglog\n","\u001b[31mERROR: torchvision 0.7.0+cu101 has requirement torch==1.6.0, but you'll have torch 1.5.1+cu92 which is incompatible.\u001b[0m\n","\u001b[31mERROR: plotnine 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 2.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 2.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 6.4.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboardX, matplotlib, ipython, proglog, imageio, imageio-ffmpeg, moviepy, EasyProcess, pyvirtualdisplay, torch, opencv-python, ipdb, box2d-py\n","  Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","  Found existing installation: ipython 5.5.0\n","    Uninstalling ipython-5.5.0:\n","      Successfully uninstalled ipython-5.5.0\n","  Found existing installation: imageio 2.4.1\n","    Uninstalling imageio-2.4.1:\n","      Successfully uninstalled imageio-2.4.1\n","  Found existing installation: moviepy 0.2.3.5\n","    Uninstalling moviepy-0.2.3.5:\n","      Successfully uninstalled moviepy-0.2.3.5\n","  Found existing installation: torch 1.6.0+cu101\n","    Uninstalling torch-1.6.0+cu101:\n","      Successfully uninstalled torch-1.6.0+cu101\n","  Found existing installation: opencv-python 3.4.0.12\n","    Uninstalling opencv-python-3.4.0.12:\n","      Successfully uninstalled opencv-python-3.4.0.12\n","Successfully installed EasyProcess-0.3 box2d-py-2.3.8 imageio-2.9.0 imageio-ffmpeg-0.4.2 ipdb-0.13.3 ipython-6.4.0 matplotlib-2.2.2 moviepy-1.0.0 opencv-python-4.4.0.42 proglog-0.1.9 pyvirtualdisplay-1.3.2 tensorboardX-1.8 torch-1.5.1+cu92\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["IPython","imageio","matplotlib","mpl_toolkits"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Obtaining file:///content/gdrive/My%20Drive/cs285_f2020/homework_fall2020/hw3\n","Installing collected packages: cs285\n","  Running setup.py develop for cs285\n","Successfully installed cs285\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g5xIOIpW8_jC","cellView":"form"},"source":["#@title set up virtual display\n","\n","from pyvirtualdisplay import Display\n","\n","display = Display(visible=0, size=(1400, 900))\n","display.start()\n","\n","# For later\n","from cs285.infrastructure.colab_utils import (\n","    wrap_env,\n","    show_video\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2rsWAWaK9BVp","cellView":"form","executionInfo":{"status":"ok","timestamp":1602178634739,"user_tz":420,"elapsed":270683,"user":{"displayName":"Yiduo Huang","photoUrl":"","userId":"07549364584604969970"}},"outputId":"5abf5ed0-f20e-4c11-ae4a-a0ac918b492d","colab":{"base_uri":"https://localhost:8080/","height":458}},"source":["#@title test virtual display\n","\n","#@markdown If you see a video of a four-legged ant fumbling about, setup is complete!\n","\n","import gym\n","import matplotlib\n","matplotlib.use('Agg')\n","\n","env = wrap_env(gym.make(\"Ant-v2\"))\n","\n","observation = env.reset()\n","for i in range(10):\n","    env.render(mode='rgb_array')\n","    obs, rew, term, _ = env.step(env.action_space.sample() ) \n","    if term:\n","      break;\n","            \n","env.close()\n","print('Loading video...')\n","show_video()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading video...\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<video alt=\"test\" autoplay \n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n","             </video>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"QizpiHDh9Fwk"},"source":["## Editing Code\n","\n","To edit code, click the folder icon on the left menu. Navigate to the corresponding file (`cs285_f2020/...`). Double click a file to open an editor. There is a timeout of about ~12 hours with Colab while it is active (and less if you close your browser window). We sync your edits to Google Drive so that you won't lose your work in the event of an instance timeout, but you will need to re-mount your Google Drive and re-install packages with every new instance."]},{"cell_type":"markdown","metadata":{"id":"Nii6qk2C9Ipk"},"source":["## Run DQN and Double DQN"]},{"cell_type":"code","metadata":{"id":"4t7FUeEG9Dkf"},"source":["#@title imports\n","import os\n","import time\n","\n","from cs285.infrastructure.rl_trainer import RL_Trainer\n","from cs285.agents.dqn_agent import DQNAgent\n","from cs285.infrastructure.dqn_utils import get_env_kwargs\n","\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2fXlzARJ9i-t","cellView":"both"},"source":["#@title runtime arguments\n","\n","class Args:\n","\n","  def __getitem__(self, key):\n","    return getattr(self, key)\n","\n","  def __setitem__(self, key, val):\n","    setattr(self, key, val)\n","\n","  def __contains__(self, key):\n","    return hasattr(self, key)\n","\n","  env_name = 'LunarLander-v3' #@param ['MsPacman-v0', 'LunarLander-v3', 'PongNoFrameSkip-v4']\n","  exp_name = 'q3_doubledqn_1' #@param\n","\n","  ## PDF will tell you how to set ep_len\n","  ## and discount for each environment\n","  ep_len = 200 #@param {type: \"integer\"}\n","\n","  #@markdown batches and steps\n","  batch_size = 32 #@param {type: \"integer\"}\n","  eval_batch_size = 1000 #@param {type: \"integer\"}\n","\n","  num_agent_train_steps_per_iter = 1 #@param {type: \"integer\"}\n","\n","  num_critic_updates_per_agent_update = 1 #@param {type: \"integer\"}\n","  \n","  #@markdown Q-learning parameters\n","  double_q = True #@param {type: \"boolean\"}\n","\n","  #@markdown system\n","  save_params = False #@param {type: \"boolean\"}\n","  no_gpu = False #@param {type: \"boolean\"}\n","  which_gpu = 0 #@param {type: \"integer\"}\n","  seed = 1 #@param {type: \"integer\"}\n","\n","  #@markdown logging\n","  ## default is to not log video so\n","  ## that logs are small enough to be\n","  ## uploaded to gradscope\n","  video_log_freq =  -1 #@param {type: \"integer\"}\n","  scalar_log_freq =  10000#@param {type: \"integer\"}\n","\n","\n","  schedule_type = 'Piecewise'\n","\n","args = Args()\n","\n","## ensure compatibility with hw1 code\n","args['train_batch_size'] = args['batch_size']\n","\n","if args['video_log_freq'] > 0:\n","  import warnings\n","  warnings.warn(\n","      '''\\nLogging videos will make eventfiles too'''\n","      '''\\nlarge for the autograder. Set video_log_freq = -1'''\n","      '''\\nfor the runs you intend to submit.''')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T0cJlp6s-ogO"},"source":["#@title create directories for logging\n","\n","data_path = '''/content/cs285_f2020/''' \\\n","        '''homework_fall2020/hw3/data'''\n","\n","if not (os.path.exists(data_path)):\n","    os.makedirs(data_path)\n","\n","logdir = args.exp_name + '_' + args.env_name + '_' + time.strftime(\"%d-%m-%Y_%H-%M-%S\")\n","logdir = os.path.join(data_path, logdir)\n","args['logdir'] = logdir\n","if not(os.path.exists(logdir)):\n","    os.makedirs(logdir)\n","\n","print(\"LOGGING TO: \", logdir)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I525KFRN-42s"},"source":["#@title Define Q-function trainer\n","\n","class Q_Trainer(object):\n","\n","    def __init__(self, params):\n","        self.params = params\n","\n","        train_args = {\n","            'num_agent_train_steps_per_iter': params['num_agent_train_steps_per_iter'],\n","            'num_critic_updates_per_agent_update': params['num_critic_updates_per_agent_update'],\n","            'train_batch_size': params['batch_size'],\n","            'double_q': params['double_q'],\n","        }\n","\n","        env_args = get_env_kwargs(params['env_name'],params['schedule_type'])\n","\n","        for k, v in env_args.items():\n","          params[k] = v\n","\n","        self.params['agent_class'] = DQNAgent\n","        self.params['agent_params'] = params\n","        self.params['train_batch_size'] = params['batch_size']\n","        self.params['env_wrappers'] = env_args['env_wrappers']\n","\n","        self.rl_trainer = RL_Trainer(self.params)\n","\n","    def run_training_loop(self):\n","        self.rl_trainer.run_training_loop(\n","            self.params['num_timesteps'],\n","            collect_policy = self.rl_trainer.agent.actor,\n","            eval_policy = self.rl_trainer.agent.actor,\n","            )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wF4LSRGn-_Cv","executionInfo":{"status":"ok","timestamp":1602183004190,"user_tz":420,"elapsed":1108118,"user":{"displayName":"Yiduo Huang","photoUrl":"","userId":"07549364584604969970"}},"outputId":"9561d47b-fff7-41fe-d3df-c86b0236c33a","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","env_names = ['LunarLander-v3', 'LunarLander-v3']\n","exp_names = ['hw3_q3_hparam2','hw3_q3_hparam3']\n","schedule_types = ['Annealing','Constant']\n","seeds = [1,1]\n","double_qs = [True, True]\n","for i in range(2):\n","    args.env_name = env_names[i]\n","    args.exp_name = exp_names[i]\n","    args.seed = seeds[i]\n","    args.double_q = double_qs[i]\n","    args.schedule_type = schedule_types[i]\n","    data_path = '''/content/cs285_f2020/''' \\\n","            '''homework_fall2020/hw3/data'''\n","    if not (os.path.exists(data_path)):\n","        os.makedirs(data_path)\n","    logdir = args.exp_name + '_' + args.env_name + '_' + time.strftime(\"%d-%m-%Y_%H-%M-%S\")\n","    logdir = os.path.join(data_path, logdir)\n","    args['logdir'] = logdir\n","    if not(os.path.exists(logdir)):\n","       os.makedirs(logdir)\n","    print(\"LOGGING TO: \", logdir)\n","    trainer = Q_Trainer(args)\n","    trainer.run_training_loop()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["LOGGING TO:  /content/cs285_f2020/homework_fall2020/hw3/data/hw3_q3_hparam2_LunarLander-v3_08-10-2020_17-39-48\n","########################\n","logging outputs to  /content/cs285_f2020/homework_fall2020/hw3/data/hw3_q3_hparam2_LunarLander-v3_08-10-2020_17-39-48\n","########################\n","Using GPU id 0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n","  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","********** Iteration 0 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 1\n","mean reward (100 episodes) nan\n","best mean reward -inf\n","running time 0.014659\n","Train_EnvstepsSoFar : 1\n","TimeSinceStart : 0.014658927917480469\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 1000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 2000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 3000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 4000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 5000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 6000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 7000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 8000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 9000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 10000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 10001\n","mean reward (100 episodes) -375.513301\n","best mean reward -inf\n","running time 39.256649\n","Train_EnvstepsSoFar : 10001\n","Train_AverageReturn : -375.51330058884\n","TimeSinceStart : 39.256648778915405\n","Training Loss : 0.675580620765686\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 11000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 12000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 13000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 14000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 15000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 16000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 17000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 18000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 19000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 20000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 20001\n","mean reward (100 episodes) -347.991057\n","best mean reward -inf\n","running time 84.600816\n","Train_EnvstepsSoFar : 20001\n","Train_AverageReturn : -347.99105670084583\n","TimeSinceStart : 84.60081553459167\n","Training Loss : 0.51275235414505\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 21000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 22000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 23000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 24000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 25000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 26000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 27000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 28000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 29000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 30000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 30001\n","mean reward (100 episodes) -322.162772\n","best mean reward -inf\n","running time 136.332881\n","Train_EnvstepsSoFar : 30001\n","Train_AverageReturn : -322.1627715289208\n","TimeSinceStart : 136.33288073539734\n","Training Loss : 0.3449903130531311\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 31000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 32000 ************\n","\n","Training agent...\n"],"name":"stdout"},{"output_type":"stream","text":["Exception ignored in: <bound method Monitor.__del__ of <Monitor<TimeLimit<LunarLander<LunarLander-v3>>>>>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/gym/wrappers/monitor.py\", line 226, in __del__\n","    self.close()\n","  File \"/usr/local/lib/python3.6/dist-packages/gym/wrappers/monitor.py\", line 135, in close\n","    self.stats_recorder.close()\n","  File \"/usr/local/lib/python3.6/dist-packages/gym/wrappers/monitoring/stats_recorder.py\", line 89, in close\n","    self.flush()\n","  File \"/usr/local/lib/python3.6/dist-packages/gym/wrappers/monitoring/stats_recorder.py\", line 96, in flush\n","    with atomic_write.atomic_write(self.path) as f:\n","  File \"/usr/lib/python3.6/contextlib.py\", line 81, in __enter__\n","    return next(self.gen)\n","  File \"/usr/local/lib/python3.6/dist-packages/gym/utils/atomic_write.py\", line 45, in atomic_write\n","    with open(tmppath, 'wb' if binary else 'w') as file:\n","FileNotFoundError: [Errno 2] No such file or directory: '/content/cs285_f2020/homework_fall2020/hw3/data/hw3_q3_hparam2_LunarLander-v3_08-10-2020_17-38-01/gym/openaigym.episode_batch.1.103.stats.json~'\n"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","********** Iteration 33000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 34000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 35000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 36000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 37000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 38000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 39000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 40000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 40001\n","mean reward (100 episodes) -300.659564\n","best mean reward -inf\n","running time 186.602424\n","Train_EnvstepsSoFar : 40001\n","Train_AverageReturn : -300.65956445618303\n","TimeSinceStart : 186.6024239063263\n","Training Loss : 0.3331739902496338\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 41000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 42000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 43000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 44000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 45000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 46000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 47000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 48000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 49000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 50000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 50001\n","mean reward (100 episodes) -265.211178\n","best mean reward -265.211178\n","running time 231.792172\n","Train_EnvstepsSoFar : 50001\n","Train_AverageReturn : -265.21117812573686\n","Train_BestReturn : -265.21117812573686\n","TimeSinceStart : 231.79217195510864\n","Training Loss : 0.3776579797267914\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 51000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 52000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 53000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 54000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 55000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 56000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 57000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 58000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 59000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 60000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 60001\n","mean reward (100 episodes) -222.116300\n","best mean reward -222.116300\n","running time 289.249958\n","Train_EnvstepsSoFar : 60001\n","Train_AverageReturn : -222.11630030549432\n","Train_BestReturn : -222.11630030549432\n","TimeSinceStart : 289.2499580383301\n","Training Loss : 0.395444393157959\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 61000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 62000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 63000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 64000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 65000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 66000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 67000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 68000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 69000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 70000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 70001\n","mean reward (100 episodes) -188.374732\n","best mean reward -188.374732\n","running time 333.809570\n","Train_EnvstepsSoFar : 70001\n","Train_AverageReturn : -188.37473183683952\n","Train_BestReturn : -188.37473183683952\n","TimeSinceStart : 333.8095703125\n","Training Loss : 0.46987485885620117\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 71000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 72000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 73000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 74000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 75000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 76000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 77000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 78000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 79000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 80000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 80001\n","mean reward (100 episodes) -141.751452\n","best mean reward -141.751452\n","running time 380.579664\n","Train_EnvstepsSoFar : 80001\n","Train_AverageReturn : -141.75145187567117\n","Train_BestReturn : -141.75145187567117\n","TimeSinceStart : 380.5796639919281\n","Training Loss : 0.7243756651878357\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 81000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 82000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 83000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 84000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 85000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 86000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 87000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 88000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 89000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 90000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 90001\n","mean reward (100 episodes) -123.546862\n","best mean reward -123.546862\n","running time 427.806698\n","Train_EnvstepsSoFar : 90001\n","Train_AverageReturn : -123.54686170160629\n","Train_BestReturn : -123.54686170160629\n","TimeSinceStart : 427.80669832229614\n","Training Loss : 0.29105913639068604\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 91000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 92000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 93000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 94000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 95000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 96000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 97000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 98000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 99000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 100000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 100001\n","mean reward (100 episodes) -97.009487\n","best mean reward -97.009487\n","running time 469.304964\n","Train_EnvstepsSoFar : 100001\n","Train_AverageReturn : -97.00948693283414\n","Train_BestReturn : -97.00948693283414\n","TimeSinceStart : 469.3049635887146\n","Training Loss : 0.21329525113105774\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 101000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 102000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 103000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 104000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 105000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 106000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 107000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 108000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 109000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 110000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 110001\n","mean reward (100 episodes) -78.757196\n","best mean reward -78.757196\n","running time 514.157712\n","Train_EnvstepsSoFar : 110001\n","Train_AverageReturn : -78.75719620242\n","Train_BestReturn : -78.75719620242\n","TimeSinceStart : 514.1577124595642\n","Training Loss : 2.8878657817840576\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 111000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 112000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 113000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 114000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 115000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 116000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 117000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 118000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 119000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 120000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 120001\n","mean reward (100 episodes) -57.614236\n","best mean reward -57.614236\n","running time 562.519715\n","Train_EnvstepsSoFar : 120001\n","Train_AverageReturn : -57.61423571786428\n","Train_BestReturn : -57.61423571786428\n","TimeSinceStart : 562.5197150707245\n","Training Loss : 0.27083516120910645\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 121000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 122000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 123000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 124000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 125000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 126000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 127000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 128000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 129000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 130000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 130001\n","mean reward (100 episodes) -33.940589\n","best mean reward -33.940589\n","running time 607.554589\n","Train_EnvstepsSoFar : 130001\n","Train_AverageReturn : -33.940589099639155\n","Train_BestReturn : -33.940589099639155\n","TimeSinceStart : 607.5545890331268\n","Training Loss : 0.16882725059986115\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 131000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 132000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 133000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 134000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 135000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 136000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 137000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 138000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 139000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 140000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 140001\n","mean reward (100 episodes) -22.911890\n","best mean reward -22.911890\n","running time 654.231182\n","Train_EnvstepsSoFar : 140001\n","Train_AverageReturn : -22.911889779852924\n","Train_BestReturn : -22.911889779852924\n","TimeSinceStart : 654.2311818599701\n","Training Loss : 0.20763343572616577\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 141000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 142000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 143000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 144000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 145000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 146000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 147000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 148000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 149000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 150000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 150001\n","mean reward (100 episodes) -21.060726\n","best mean reward -21.060726\n","running time 702.352058\n","Train_EnvstepsSoFar : 150001\n","Train_AverageReturn : -21.06072647477773\n","Train_BestReturn : -21.06072647477773\n","TimeSinceStart : 702.3520576953888\n","Training Loss : 0.252067506313324\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 151000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 152000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 153000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 154000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 155000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 156000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 157000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 158000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 159000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 160000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 160001\n","mean reward (100 episodes) -11.261623\n","best mean reward -11.261623\n","running time 748.145713\n","Train_EnvstepsSoFar : 160001\n","Train_AverageReturn : -11.261622918261908\n","Train_BestReturn : -11.261622918261908\n","TimeSinceStart : 748.1457133293152\n","Training Loss : 0.21174663305282593\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 161000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 162000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 163000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 164000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 165000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 166000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 167000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 168000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 169000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 170000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 170001\n","mean reward (100 episodes) -11.351703\n","best mean reward -11.261623\n","running time 795.664613\n","Train_EnvstepsSoFar : 170001\n","Train_AverageReturn : -11.35170308787845\n","Train_BestReturn : -11.261622918261908\n","TimeSinceStart : 795.6646130084991\n","Training Loss : 0.11992104351520538\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 171000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 172000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 173000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 174000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 175000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 176000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 177000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 178000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 179000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 180000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 180001\n","mean reward (100 episodes) -6.026832\n","best mean reward -6.026832\n","running time 844.759782\n","Train_EnvstepsSoFar : 180001\n","Train_AverageReturn : -6.026832150280377\n","Train_BestReturn : -6.026832150280377\n","TimeSinceStart : 844.7597818374634\n","Training Loss : 0.15601536631584167\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 181000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 182000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 183000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 184000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 185000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 186000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 187000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 188000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 189000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 190000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 190001\n","mean reward (100 episodes) 4.138643\n","best mean reward 4.138643\n","running time 891.184156\n","Train_EnvstepsSoFar : 190001\n","Train_AverageReturn : 4.138643407196679\n","Train_BestReturn : 4.138643407196679\n","TimeSinceStart : 891.1841561794281\n","Training Loss : 0.10447797179222107\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 191000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 192000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 193000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 194000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 195000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 196000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 197000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 198000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 199000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 200000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 200001\n","mean reward (100 episodes) 4.815356\n","best mean reward 4.815356\n","running time 942.783171\n","Train_EnvstepsSoFar : 200001\n","Train_AverageReturn : 4.815355911436013\n","Train_BestReturn : 4.815355911436013\n","TimeSinceStart : 942.783171415329\n","Training Loss : 0.14918546378612518\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 201000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 202000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 203000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 204000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 205000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 206000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 207000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 208000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 209000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 210000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 210001\n","mean reward (100 episodes) 9.605195\n","best mean reward 9.605195\n","running time 989.896179\n","Train_EnvstepsSoFar : 210001\n","Train_AverageReturn : 9.605194696661307\n","Train_BestReturn : 9.605194696661307\n","TimeSinceStart : 989.8961791992188\n","Training Loss : 0.7147799134254456\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 211000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 212000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 213000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 214000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 215000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 216000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 217000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 218000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 219000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 220000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 220001\n","mean reward (100 episodes) 31.525019\n","best mean reward 31.525019\n","running time 1037.507146\n","Train_EnvstepsSoFar : 220001\n","Train_AverageReturn : 31.525018994000906\n","Train_BestReturn : 31.525018994000906\n","TimeSinceStart : 1037.5071458816528\n","Training Loss : 0.21969473361968994\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 221000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 222000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 223000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 224000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 225000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 226000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 227000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 228000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 229000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 230000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 230001\n","mean reward (100 episodes) 24.824173\n","best mean reward 31.525019\n","running time 1085.105339\n","Train_EnvstepsSoFar : 230001\n","Train_AverageReturn : 24.824173303650856\n","Train_BestReturn : 31.525018994000906\n","TimeSinceStart : 1085.1053392887115\n","Training Loss : 0.06785213202238083\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 231000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 232000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 233000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 234000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 235000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 236000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 237000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 238000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 239000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 240000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 240001\n","mean reward (100 episodes) 31.445164\n","best mean reward 31.525019\n","running time 1134.216676\n","Train_EnvstepsSoFar : 240001\n","Train_AverageReturn : 31.44516357425489\n","Train_BestReturn : 31.525018994000906\n","TimeSinceStart : 1134.2166759967804\n","Training Loss : 0.0976305678486824\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 241000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 242000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 243000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 244000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 245000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 246000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 247000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 248000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 249000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 250000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 250001\n","mean reward (100 episodes) 32.311953\n","best mean reward 32.311953\n","running time 1182.828160\n","Train_EnvstepsSoFar : 250001\n","Train_AverageReturn : 32.311953284345144\n","Train_BestReturn : 32.311953284345144\n","TimeSinceStart : 1182.8281598091125\n","Training Loss : 0.05817720293998718\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 251000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 252000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 253000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 254000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 255000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 256000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 257000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 258000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 259000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 260000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 260001\n","mean reward (100 episodes) 38.244063\n","best mean reward 38.244063\n","running time 1230.706903\n","Train_EnvstepsSoFar : 260001\n","Train_AverageReturn : 38.24406308148588\n","Train_BestReturn : 38.24406308148588\n","TimeSinceStart : 1230.7069025039673\n","Training Loss : 0.06954799592494965\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 261000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 262000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 263000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 264000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 265000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 266000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 267000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 268000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 269000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 270000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 270001\n","mean reward (100 episodes) 44.847288\n","best mean reward 44.847288\n","running time 1277.358997\n","Train_EnvstepsSoFar : 270001\n","Train_AverageReturn : 44.847287679002385\n","Train_BestReturn : 44.847287679002385\n","TimeSinceStart : 1277.3589971065521\n","Training Loss : 0.07267816364765167\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 271000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 272000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 273000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 274000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 275000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 276000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 277000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 278000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 279000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 280000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 280001\n","mean reward (100 episodes) 45.533311\n","best mean reward 45.533311\n","running time 1324.995287\n","Train_EnvstepsSoFar : 280001\n","Train_AverageReturn : 45.533311293683646\n","Train_BestReturn : 45.533311293683646\n","TimeSinceStart : 1324.995287179947\n","Training Loss : 0.20343074202537537\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 281000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 282000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 283000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 284000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 285000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 286000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 287000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 288000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 289000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 290000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 290001\n","mean reward (100 episodes) 66.921760\n","best mean reward 66.921760\n","running time 1368.060479\n","Train_EnvstepsSoFar : 290001\n","Train_AverageReturn : 66.9217604758544\n","Train_BestReturn : 66.9217604758544\n","TimeSinceStart : 1368.0604786872864\n","Training Loss : 0.12308596819639206\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 291000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 292000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 293000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 294000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 295000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 296000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 297000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 298000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 299000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 300000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 300001\n","mean reward (100 episodes) 80.885202\n","best mean reward 80.885202\n","running time 1422.061852\n","Train_EnvstepsSoFar : 300001\n","Train_AverageReturn : 80.88520174593633\n","Train_BestReturn : 80.88520174593633\n","TimeSinceStart : 1422.061851978302\n","Training Loss : 0.15109603106975555\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 301000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 302000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 303000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 304000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 305000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 306000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 307000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 308000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 309000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 310000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 310001\n","mean reward (100 episodes) 96.598713\n","best mean reward 96.598713\n","running time 1463.698014\n","Train_EnvstepsSoFar : 310001\n","Train_AverageReturn : 96.59871284669562\n","Train_BestReturn : 96.59871284669562\n","TimeSinceStart : 1463.6980135440826\n","Training Loss : 0.1457253247499466\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 311000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 312000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 313000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 314000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 315000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 316000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 317000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 318000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 319000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 320000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 320001\n","mean reward (100 episodes) 115.937863\n","best mean reward 115.937863\n","running time 1501.352477\n","Train_EnvstepsSoFar : 320001\n","Train_AverageReturn : 115.93786290996515\n","Train_BestReturn : 115.93786290996515\n","TimeSinceStart : 1501.352477312088\n","Training Loss : 0.06400982290506363\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 321000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 322000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 323000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 324000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 325000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 326000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 327000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 328000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 329000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 330000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 330001\n","mean reward (100 episodes) 125.767573\n","best mean reward 125.767573\n","running time 1542.153069\n","Train_EnvstepsSoFar : 330001\n","Train_AverageReturn : 125.76757269661479\n","Train_BestReturn : 125.76757269661479\n","TimeSinceStart : 1542.1530692577362\n","Training Loss : 0.12190283834934235\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 331000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 332000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 333000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 334000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 335000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 336000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 337000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 338000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 339000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 340000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 340001\n","mean reward (100 episodes) 95.664249\n","best mean reward 125.767573\n","running time 1578.707798\n","Train_EnvstepsSoFar : 340001\n","Train_AverageReturn : 95.66424855779023\n","Train_BestReturn : 125.76757269661479\n","TimeSinceStart : 1578.7077977657318\n","Training Loss : 0.08692603558301926\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 341000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 342000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 343000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 344000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 345000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 346000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 347000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 348000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 349000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 350000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 350001\n","mean reward (100 episodes) 48.559781\n","best mean reward 125.767573\n","running time 1618.654056\n","Train_EnvstepsSoFar : 350001\n","Train_AverageReturn : 48.55978125139114\n","Train_BestReturn : 125.76757269661479\n","TimeSinceStart : 1618.654055595398\n","Training Loss : 0.2402115762233734\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 351000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 352000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 353000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 354000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 355000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 356000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 357000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 358000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 359000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 360000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 360001\n","mean reward (100 episodes) 83.942647\n","best mean reward 125.767573\n","running time 1657.591471\n","Train_EnvstepsSoFar : 360001\n","Train_AverageReturn : 83.94264712265186\n","Train_BestReturn : 125.76757269661479\n","TimeSinceStart : 1657.5914714336395\n","Training Loss : 0.22061005234718323\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 361000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 362000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 363000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 364000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 365000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 366000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 367000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 368000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 369000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 370000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 370001\n","mean reward (100 episodes) 79.741520\n","best mean reward 125.767573\n","running time 1695.261906\n","Train_EnvstepsSoFar : 370001\n","Train_AverageReturn : 79.7415195587913\n","Train_BestReturn : 125.76757269661479\n","TimeSinceStart : 1695.261905670166\n","Training Loss : 1.695845127105713\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 371000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 372000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 373000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 374000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 375000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 376000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 377000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 378000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 379000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 380000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 380001\n","mean reward (100 episodes) 57.667818\n","best mean reward 125.767573\n","running time 1734.446344\n","Train_EnvstepsSoFar : 380001\n","Train_AverageReturn : 57.66781790176542\n","Train_BestReturn : 125.76757269661479\n","TimeSinceStart : 1734.4463438987732\n","Training Loss : 3.012566566467285\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 381000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 382000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 383000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 384000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 385000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 386000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 387000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 388000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 389000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 390000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 390001\n","mean reward (100 episodes) 80.415777\n","best mean reward 125.767573\n","running time 1770.960781\n","Train_EnvstepsSoFar : 390001\n","Train_AverageReturn : 80.41577704476795\n","Train_BestReturn : 125.76757269661479\n","TimeSinceStart : 1770.9607813358307\n","Training Loss : 4.347150802612305\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 391000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 392000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 393000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 394000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 395000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 396000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 397000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 398000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 399000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 400000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 400001\n","mean reward (100 episodes) 98.333284\n","best mean reward 125.767573\n","running time 1812.048681\n","Train_EnvstepsSoFar : 400001\n","Train_AverageReturn : 98.33328377596548\n","Train_BestReturn : 125.76757269661479\n","TimeSinceStart : 1812.0486807823181\n","Training Loss : 0.46193718910217285\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 401000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 402000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 403000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 404000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 405000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 406000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 407000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 408000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 409000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 410000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 410001\n","mean reward (100 episodes) 112.139758\n","best mean reward 125.767573\n","running time 1851.711322\n","Train_EnvstepsSoFar : 410001\n","Train_AverageReturn : 112.13975785659731\n","Train_BestReturn : 125.76757269661479\n","TimeSinceStart : 1851.711322069168\n","Training Loss : 3.464285373687744\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 411000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 412000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 413000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 414000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 415000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 416000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 417000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 418000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 419000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 420000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 420001\n","mean reward (100 episodes) 130.566435\n","best mean reward 130.566435\n","running time 1887.295310\n","Train_EnvstepsSoFar : 420001\n","Train_AverageReturn : 130.56643499143522\n","Train_BestReturn : 130.56643499143522\n","TimeSinceStart : 1887.2953100204468\n","Training Loss : 0.5487108826637268\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 421000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 422000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 423000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 424000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 425000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 426000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 427000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 428000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 429000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 430000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 430001\n","mean reward (100 episodes) 140.073124\n","best mean reward 140.073124\n","running time 1922.523568\n","Train_EnvstepsSoFar : 430001\n","Train_AverageReturn : 140.07312396427272\n","Train_BestReturn : 140.07312396427272\n","TimeSinceStart : 1922.5235681533813\n","Training Loss : 0.22667327523231506\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 431000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 432000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 433000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 434000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 435000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 436000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 437000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 438000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 439000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 440000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 440001\n","mean reward (100 episodes) 143.084227\n","best mean reward 143.084227\n","running time 1957.461951\n","Train_EnvstepsSoFar : 440001\n","Train_AverageReturn : 143.0842269907495\n","Train_BestReturn : 143.0842269907495\n","TimeSinceStart : 1957.4619510173798\n","Training Loss : 0.27033764123916626\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 441000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 442000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 443000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 444000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 445000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 446000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 447000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 448000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 449000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 450000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 450001\n","mean reward (100 episodes) 162.971695\n","best mean reward 162.971695\n","running time 1992.311326\n","Train_EnvstepsSoFar : 450001\n","Train_AverageReturn : 162.97169535048764\n","Train_BestReturn : 162.97169535048764\n","TimeSinceStart : 1992.311325788498\n","Training Loss : 0.37237975001335144\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 451000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 452000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 453000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 454000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 455000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 456000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 457000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 458000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 459000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 460000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 460001\n","mean reward (100 episodes) 153.913956\n","best mean reward 162.971695\n","running time 2027.256712\n","Train_EnvstepsSoFar : 460001\n","Train_AverageReturn : 153.91395646067474\n","Train_BestReturn : 162.97169535048764\n","TimeSinceStart : 2027.256712436676\n","Training Loss : 0.27668315172195435\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 461000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 462000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 463000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 464000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 465000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 466000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 467000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 468000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 469000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 470000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 470001\n","mean reward (100 episodes) 149.010440\n","best mean reward 162.971695\n","running time 2062.290356\n","Train_EnvstepsSoFar : 470001\n","Train_AverageReturn : 149.01043980427383\n","Train_BestReturn : 162.97169535048764\n","TimeSinceStart : 2062.29035615921\n","Training Loss : 5.382602214813232\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 471000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 472000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 473000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 474000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 475000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 476000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 477000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 478000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 479000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 480000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 480001\n","mean reward (100 episodes) 123.727747\n","best mean reward 162.971695\n","running time 2097.214131\n","Train_EnvstepsSoFar : 480001\n","Train_AverageReturn : 123.72774698639698\n","Train_BestReturn : 162.97169535048764\n","TimeSinceStart : 2097.21413064003\n","Training Loss : 2.8013627529144287\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 481000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 482000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 483000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 484000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 485000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 486000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 487000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 488000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 489000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 490000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 490001\n","mean reward (100 episodes) 119.559720\n","best mean reward 162.971695\n","running time 2131.826364\n","Train_EnvstepsSoFar : 490001\n","Train_AverageReturn : 119.55972011928402\n","Train_BestReturn : 162.97169535048764\n","TimeSinceStart : 2131.826363801956\n","Training Loss : 0.27739858627319336\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 491000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 492000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 493000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 494000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 495000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 496000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 497000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 498000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 499000 ************\n","\n","Training agent...\n","LOGGING TO:  /content/cs285_f2020/homework_fall2020/hw3/data/hw3_q3_hparam3_LunarLander-v3_08-10-2020_18-15-54\n","########################\n","logging outputs to  /content/cs285_f2020/homework_fall2020/hw3/data/hw3_q3_hparam3_LunarLander-v3_08-10-2020_18-15-54\n","########################\n","Using GPU id 0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n","  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","********** Iteration 0 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 1\n","mean reward (100 episodes) nan\n","best mean reward -inf\n","running time 0.012550\n","Train_EnvstepsSoFar : 1\n","TimeSinceStart : 0.012550115585327148\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 1000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 2000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 3000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 4000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 5000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 6000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 7000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 8000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 9000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 10000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 10001\n","mean reward (100 episodes) -316.961420\n","best mean reward -inf\n","running time 44.202707\n","Train_EnvstepsSoFar : 10001\n","Train_AverageReturn : -316.96142013006\n","TimeSinceStart : 44.20270657539368\n","Training Loss : 0.44481784105300903\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 11000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 12000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 13000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 14000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 15000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 16000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 17000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 18000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 19000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 20000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 20001\n","mean reward (100 episodes) -296.617779\n","best mean reward -inf\n","running time 89.436493\n","Train_EnvstepsSoFar : 20001\n","Train_AverageReturn : -296.61777925843506\n","TimeSinceStart : 89.43649315834045\n","Training Loss : 0.33263900876045227\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 21000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 22000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 23000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 24000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 25000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 26000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 27000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 28000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 29000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 30000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 30001\n","mean reward (100 episodes) -264.523582\n","best mean reward -inf\n","running time 148.877344\n","Train_EnvstepsSoFar : 30001\n","Train_AverageReturn : -264.52358203055525\n","TimeSinceStart : 148.87734389305115\n","Training Loss : 1.700232982635498\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 31000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 32000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 33000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 34000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 35000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 36000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 37000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 38000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 39000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 40000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 40001\n","mean reward (100 episodes) -241.746430\n","best mean reward -inf\n","running time 195.935993\n","Train_EnvstepsSoFar : 40001\n","Train_AverageReturn : -241.74643025939542\n","TimeSinceStart : 195.93599319458008\n","Training Loss : 0.5604068636894226\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 41000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 42000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 43000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 44000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 45000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 46000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 47000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 48000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 49000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 50000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 50001\n","mean reward (100 episodes) -224.921805\n","best mean reward -inf\n","running time 240.615396\n","Train_EnvstepsSoFar : 50001\n","Train_AverageReturn : -224.92180507665685\n","TimeSinceStart : 240.6153964996338\n","Training Loss : 0.29436883330345154\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 51000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 52000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 53000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 54000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 55000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 56000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 57000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 58000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 59000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 60000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 60001\n","mean reward (100 episodes) -186.540739\n","best mean reward -186.540739\n","running time 286.248650\n","Train_EnvstepsSoFar : 60001\n","Train_AverageReturn : -186.54073889607218\n","Train_BestReturn : -186.54073889607218\n","TimeSinceStart : 286.24864959716797\n","Training Loss : 0.11044125258922577\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 61000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 62000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 63000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 64000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 65000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 66000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 67000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 68000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 69000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 70000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 70001\n","mean reward (100 episodes) -142.837195\n","best mean reward -142.837195\n","running time 344.316546\n","Train_EnvstepsSoFar : 70001\n","Train_AverageReturn : -142.83719516565708\n","Train_BestReturn : -142.83719516565708\n","TimeSinceStart : 344.31654596328735\n","Training Loss : 0.16100578010082245\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 71000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 72000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 73000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 74000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 75000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 76000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 77000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 78000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 79000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 80000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 80001\n","mean reward (100 episodes) -109.868407\n","best mean reward -109.868407\n","running time 391.568530\n","Train_EnvstepsSoFar : 80001\n","Train_AverageReturn : -109.86840695996288\n","Train_BestReturn : -109.86840695996288\n","TimeSinceStart : 391.56852984428406\n","Training Loss : 1.326494812965393\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 81000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 82000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 83000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 84000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 85000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 86000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 87000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 88000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 89000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 90000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 90001\n","mean reward (100 episodes) -85.665583\n","best mean reward -85.665583\n","running time 436.985235\n","Train_EnvstepsSoFar : 90001\n","Train_AverageReturn : -85.66558299208992\n","Train_BestReturn : -85.66558299208992\n","TimeSinceStart : 436.9852349758148\n","Training Loss : 0.37157848477363586\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 91000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 92000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 93000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 94000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 95000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 96000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 97000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 98000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 99000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 100000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 100001\n","mean reward (100 episodes) -60.360211\n","best mean reward -60.360211\n","running time 483.495149\n","Train_EnvstepsSoFar : 100001\n","Train_AverageReturn : -60.36021074189898\n","Train_BestReturn : -60.36021074189898\n","TimeSinceStart : 483.495148897171\n","Training Loss : 0.23260703682899475\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 101000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 102000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 103000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 104000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 105000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 106000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 107000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 108000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 109000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 110000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 110001\n","mean reward (100 episodes) -43.478211\n","best mean reward -43.478211\n","running time 529.639585\n","Train_EnvstepsSoFar : 110001\n","Train_AverageReturn : -43.478210524631265\n","Train_BestReturn : -43.478210524631265\n","TimeSinceStart : 529.6395854949951\n","Training Loss : 0.2878267765045166\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 111000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 112000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 113000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 114000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 115000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 116000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 117000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 118000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 119000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 120000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 120001\n","mean reward (100 episodes) -23.070764\n","best mean reward -23.070764\n","running time 575.892725\n","Train_EnvstepsSoFar : 120001\n","Train_AverageReturn : -23.070763559206995\n","Train_BestReturn : -23.070763559206995\n","TimeSinceStart : 575.8927249908447\n","Training Loss : 0.5194118022918701\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 121000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 122000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 123000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 124000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 125000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 126000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 127000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 128000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 129000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 130000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 130001\n","mean reward (100 episodes) -7.297392\n","best mean reward -7.297392\n","running time 621.440777\n","Train_EnvstepsSoFar : 130001\n","Train_AverageReturn : -7.297392339507778\n","Train_BestReturn : -7.297392339507778\n","TimeSinceStart : 621.4407765865326\n","Training Loss : 0.21975257992744446\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 131000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 132000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 133000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 134000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 135000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 136000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 137000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 138000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 139000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 140000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 140001\n","mean reward (100 episodes) 8.328001\n","best mean reward 8.328001\n","running time 669.003785\n","Train_EnvstepsSoFar : 140001\n","Train_AverageReturn : 8.328001465905606\n","Train_BestReturn : 8.328001465905606\n","TimeSinceStart : 669.0037846565247\n","Training Loss : 0.48386919498443604\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 141000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 142000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 143000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 144000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 145000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 146000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 147000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 148000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 149000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 150000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 150001\n","mean reward (100 episodes) 35.091312\n","best mean reward 35.091312\n","running time 711.700021\n","Train_EnvstepsSoFar : 150001\n","Train_AverageReturn : 35.09131192828734\n","Train_BestReturn : 35.09131192828734\n","TimeSinceStart : 711.7000210285187\n","Training Loss : 0.21163110435009003\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 151000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 152000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 153000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 154000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 155000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 156000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 157000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 158000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 159000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 160000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 160001\n","mean reward (100 episodes) 58.970601\n","best mean reward 58.970601\n","running time 753.807535\n","Train_EnvstepsSoFar : 160001\n","Train_AverageReturn : 58.97060116022235\n","Train_BestReturn : 58.97060116022235\n","TimeSinceStart : 753.8075354099274\n","Training Loss : 1.3558608293533325\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 161000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 162000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 163000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 164000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 165000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 166000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 167000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 168000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 169000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 170000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 170001\n","mean reward (100 episodes) 103.075061\n","best mean reward 103.075061\n","running time 791.425931\n","Train_EnvstepsSoFar : 170001\n","Train_AverageReturn : 103.0750613298645\n","Train_BestReturn : 103.0750613298645\n","TimeSinceStart : 791.4259312152863\n","Training Loss : 0.1273471862077713\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 171000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 172000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 173000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 174000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 175000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 176000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 177000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 178000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 179000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 180000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 180001\n","mean reward (100 episodes) 112.737572\n","best mean reward 112.737572\n","running time 833.556625\n","Train_EnvstepsSoFar : 180001\n","Train_AverageReturn : 112.73757201229337\n","Train_BestReturn : 112.73757201229337\n","TimeSinceStart : 833.5566248893738\n","Training Loss : 0.15193668007850647\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 181000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 182000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 183000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 184000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 185000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 186000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 187000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 188000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 189000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 190000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 190001\n","mean reward (100 episodes) 118.612975\n","best mean reward 118.612975\n","running time 878.786659\n","Train_EnvstepsSoFar : 190001\n","Train_AverageReturn : 118.61297467735592\n","Train_BestReturn : 118.61297467735592\n","TimeSinceStart : 878.7866587638855\n","Training Loss : 1.1146931648254395\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 191000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 192000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 193000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 194000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 195000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 196000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 197000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 198000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 199000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 200000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 200001\n","mean reward (100 episodes) 100.694238\n","best mean reward 118.612975\n","running time 921.849605\n","Train_EnvstepsSoFar : 200001\n","Train_AverageReturn : 100.6942379330957\n","Train_BestReturn : 118.61297467735592\n","TimeSinceStart : 921.8496046066284\n","Training Loss : 0.3329097330570221\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 201000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 202000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 203000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 204000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 205000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 206000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 207000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 208000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 209000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 210000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 210001\n","mean reward (100 episodes) 77.874416\n","best mean reward 118.612975\n","running time 963.235344\n","Train_EnvstepsSoFar : 210001\n","Train_AverageReturn : 77.87441584671184\n","Train_BestReturn : 118.61297467735592\n","TimeSinceStart : 963.235344171524\n","Training Loss : 1.8353543281555176\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 211000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 212000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 213000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 214000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 215000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 216000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 217000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 218000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 219000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 220000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 220001\n","mean reward (100 episodes) 76.351254\n","best mean reward 118.612975\n","running time 1002.925683\n","Train_EnvstepsSoFar : 220001\n","Train_AverageReturn : 76.35125420358185\n","Train_BestReturn : 118.61297467735592\n","TimeSinceStart : 1002.9256830215454\n","Training Loss : 2.695427656173706\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 221000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 222000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 223000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 224000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 225000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 226000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 227000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 228000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 229000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 230000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 230001\n","mean reward (100 episodes) 69.034347\n","best mean reward 118.612975\n","running time 1046.186189\n","Train_EnvstepsSoFar : 230001\n","Train_AverageReturn : 69.03434722347858\n","Train_BestReturn : 118.61297467735592\n","TimeSinceStart : 1046.186188697815\n","Training Loss : 1.7537375688552856\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 231000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 232000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 233000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 234000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 235000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 236000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 237000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 238000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 239000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 240000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 240001\n","mean reward (100 episodes) 92.064841\n","best mean reward 118.612975\n","running time 1081.804114\n","Train_EnvstepsSoFar : 240001\n","Train_AverageReturn : 92.06484091302609\n","Train_BestReturn : 118.61297467735592\n","TimeSinceStart : 1081.80411362648\n","Training Loss : 0.1504925638437271\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 241000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 242000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 243000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 244000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 245000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 246000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 247000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 248000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 249000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 250000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 250001\n","mean reward (100 episodes) 99.546392\n","best mean reward 118.612975\n","running time 1123.459793\n","Train_EnvstepsSoFar : 250001\n","Train_AverageReturn : 99.54639219164432\n","Train_BestReturn : 118.61297467735592\n","TimeSinceStart : 1123.4597928524017\n","Training Loss : 1.1723088026046753\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 251000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 252000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 253000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 254000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 255000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 256000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 257000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 258000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 259000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 260000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 260001\n","mean reward (100 episodes) 103.870026\n","best mean reward 118.612975\n","running time 1163.299482\n","Train_EnvstepsSoFar : 260001\n","Train_AverageReturn : 103.87002560807592\n","Train_BestReturn : 118.61297467735592\n","TimeSinceStart : 1163.299481868744\n","Training Loss : 0.18418455123901367\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 261000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 262000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 263000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 264000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 265000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 266000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 267000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 268000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 269000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 270000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 270001\n","mean reward (100 episodes) 103.133980\n","best mean reward 118.612975\n","running time 1206.757141\n","Train_EnvstepsSoFar : 270001\n","Train_AverageReturn : 103.13397985493252\n","Train_BestReturn : 118.61297467735592\n","TimeSinceStart : 1206.7571411132812\n","Training Loss : 0.26181772351264954\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 271000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 272000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 273000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 274000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 275000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 276000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 277000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 278000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 279000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 280000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 280001\n","mean reward (100 episodes) 115.448182\n","best mean reward 118.612975\n","running time 1245.302492\n","Train_EnvstepsSoFar : 280001\n","Train_AverageReturn : 115.44818168460118\n","Train_BestReturn : 118.61297467735592\n","TimeSinceStart : 1245.3024923801422\n","Training Loss : 0.1801932007074356\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 281000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 282000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 283000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 284000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 285000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 286000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 287000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 288000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 289000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 290000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 290001\n","mean reward (100 episodes) 121.367429\n","best mean reward 121.367429\n","running time 1282.406706\n","Train_EnvstepsSoFar : 290001\n","Train_AverageReturn : 121.36742869429894\n","Train_BestReturn : 121.36742869429894\n","TimeSinceStart : 1282.4067060947418\n","Training Loss : 0.1767951101064682\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 291000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 292000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 293000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 294000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 295000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 296000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 297000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 298000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 299000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 300000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 300001\n","mean reward (100 episodes) 120.097528\n","best mean reward 121.367429\n","running time 1319.443082\n","Train_EnvstepsSoFar : 300001\n","Train_AverageReturn : 120.09752771545129\n","Train_BestReturn : 121.36742869429894\n","TimeSinceStart : 1319.443081855774\n","Training Loss : 0.09699104726314545\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 301000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 302000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 303000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 304000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 305000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 306000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 307000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 308000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 309000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 310000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 310001\n","mean reward (100 episodes) 122.980851\n","best mean reward 122.980851\n","running time 1358.191285\n","Train_EnvstepsSoFar : 310001\n","Train_AverageReturn : 122.98085099321821\n","Train_BestReturn : 122.98085099321821\n","TimeSinceStart : 1358.1912846565247\n","Training Loss : 9.122167587280273\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 311000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 312000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 313000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 314000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 315000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 316000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 317000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 318000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 319000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 320000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 320001\n","mean reward (100 episodes) 125.873252\n","best mean reward 125.873252\n","running time 1393.042281\n","Train_EnvstepsSoFar : 320001\n","Train_AverageReturn : 125.87325178803174\n","Train_BestReturn : 125.87325178803174\n","TimeSinceStart : 1393.0422811508179\n","Training Loss : 0.5483078360557556\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 321000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 322000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 323000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 324000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 325000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 326000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 327000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 328000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 329000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 330000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 330001\n","mean reward (100 episodes) 94.450046\n","best mean reward 125.873252\n","running time 1428.033695\n","Train_EnvstepsSoFar : 330001\n","Train_AverageReturn : 94.45004641541408\n","Train_BestReturn : 125.87325178803174\n","TimeSinceStart : 1428.0336949825287\n","Training Loss : 5.337403774261475\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 331000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 332000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 333000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 334000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 335000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 336000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 337000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 338000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 339000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 340000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 340001\n","mean reward (100 episodes) 94.259872\n","best mean reward 125.873252\n","running time 1463.000797\n","Train_EnvstepsSoFar : 340001\n","Train_AverageReturn : 94.25987233582975\n","Train_BestReturn : 125.87325178803174\n","TimeSinceStart : 1463.0007965564728\n","Training Loss : 4.515439033508301\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 341000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 342000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 343000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 344000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 345000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 346000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 347000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 348000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 349000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 350000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 350001\n","mean reward (100 episodes) 117.921489\n","best mean reward 125.873252\n","running time 1498.507760\n","Train_EnvstepsSoFar : 350001\n","Train_AverageReturn : 117.92148923888725\n","Train_BestReturn : 125.87325178803174\n","TimeSinceStart : 1498.5077595710754\n","Training Loss : 0.3480263352394104\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 351000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 352000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 353000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 354000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 355000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 356000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 357000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 358000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 359000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 360000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 360001\n","mean reward (100 episodes) 89.040517\n","best mean reward 125.873252\n","running time 1538.173170\n","Train_EnvstepsSoFar : 360001\n","Train_AverageReturn : 89.04051669933439\n","Train_BestReturn : 125.87325178803174\n","TimeSinceStart : 1538.1731700897217\n","Training Loss : 0.16837772727012634\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 361000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 362000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 363000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 364000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 365000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 366000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 367000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 368000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 369000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 370000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 370001\n","mean reward (100 episodes) 64.504273\n","best mean reward 125.873252\n","running time 1574.703357\n","Train_EnvstepsSoFar : 370001\n","Train_AverageReturn : 64.50427258025549\n","Train_BestReturn : 125.87325178803174\n","TimeSinceStart : 1574.7033569812775\n","Training Loss : 0.17776061594486237\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 371000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 372000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 373000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 374000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 375000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 376000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 377000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 378000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 379000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 380000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 380001\n","mean reward (100 episodes) 37.643619\n","best mean reward 125.873252\n","running time 1610.103762\n","Train_EnvstepsSoFar : 380001\n","Train_AverageReturn : 37.64361940513847\n","Train_BestReturn : 125.87325178803174\n","TimeSinceStart : 1610.1037623882294\n","Training Loss : 0.6042281985282898\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 381000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 382000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 383000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 384000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 385000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 386000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 387000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 388000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 389000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 390000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 390001\n","mean reward (100 episodes) 27.812860\n","best mean reward 125.873252\n","running time 1646.019245\n","Train_EnvstepsSoFar : 390001\n","Train_AverageReturn : 27.812860437798687\n","Train_BestReturn : 125.87325178803174\n","TimeSinceStart : 1646.019245147705\n","Training Loss : 0.8535772562026978\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 391000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 392000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 393000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 394000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 395000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 396000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 397000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 398000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 399000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 400000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 400001\n","mean reward (100 episodes) 8.639710\n","best mean reward 125.873252\n","running time 1681.800073\n","Train_EnvstepsSoFar : 400001\n","Train_AverageReturn : 8.639709758325465\n","Train_BestReturn : 125.87325178803174\n","TimeSinceStart : 1681.8000733852386\n","Training Loss : 0.2113405466079712\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 401000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 402000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 403000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 404000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 405000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 406000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 407000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 408000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 409000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 410000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 410001\n","mean reward (100 episodes) 31.399775\n","best mean reward 125.873252\n","running time 1718.178073\n","Train_EnvstepsSoFar : 410001\n","Train_AverageReturn : 31.39977541687105\n","Train_BestReturn : 125.87325178803174\n","TimeSinceStart : 1718.1780726909637\n","Training Loss : 0.12727777659893036\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 411000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 412000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 413000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 414000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 415000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 416000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 417000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 418000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 419000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 420000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 420001\n","mean reward (100 episodes) 12.657560\n","best mean reward 125.873252\n","running time 1753.813179\n","Train_EnvstepsSoFar : 420001\n","Train_AverageReturn : 12.65755999555229\n","Train_BestReturn : 125.87325178803174\n","TimeSinceStart : 1753.8131787776947\n","Training Loss : 0.2796490490436554\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 421000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 422000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 423000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 424000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 425000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 426000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 427000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 428000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 429000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 430000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 430001\n","mean reward (100 episodes) 11.566139\n","best mean reward 125.873252\n","running time 1789.742337\n","Train_EnvstepsSoFar : 430001\n","Train_AverageReturn : 11.56613884872496\n","Train_BestReturn : 125.87325178803174\n","TimeSinceStart : 1789.7423367500305\n","Training Loss : 0.18764728307724\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 431000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 432000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 433000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 434000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 435000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 436000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 437000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 438000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 439000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 440000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 440001\n","mean reward (100 episodes) 19.751429\n","best mean reward 125.873252\n","running time 1826.255260\n","Train_EnvstepsSoFar : 440001\n","Train_AverageReturn : 19.75142886539381\n","Train_BestReturn : 125.87325178803174\n","TimeSinceStart : 1826.2552604675293\n","Training Loss : 0.4262353181838989\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 441000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 442000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 443000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 444000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 445000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 446000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 447000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 448000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 449000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 450000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 450001\n","mean reward (100 episodes) 47.992949\n","best mean reward 125.873252\n","running time 1862.903245\n","Train_EnvstepsSoFar : 450001\n","Train_AverageReturn : 47.992949126137006\n","Train_BestReturn : 125.87325178803174\n","TimeSinceStart : 1862.9032454490662\n","Training Loss : 0.27051106095314026\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 451000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 452000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 453000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 454000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 455000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 456000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 457000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 458000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 459000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 460000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 460001\n","mean reward (100 episodes) 82.014157\n","best mean reward 125.873252\n","running time 1898.718218\n","Train_EnvstepsSoFar : 460001\n","Train_AverageReturn : 82.01415748441444\n","Train_BestReturn : 125.87325178803174\n","TimeSinceStart : 1898.7182178497314\n","Training Loss : 2.472520589828491\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 461000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 462000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 463000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 464000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 465000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 466000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 467000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 468000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 469000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 470000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 470001\n","mean reward (100 episodes) 97.932065\n","best mean reward 125.873252\n","running time 1934.292331\n","Train_EnvstepsSoFar : 470001\n","Train_AverageReturn : 97.93206452975066\n","Train_BestReturn : 125.87325178803174\n","TimeSinceStart : 1934.2923305034637\n","Training Loss : 0.1940661072731018\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 471000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 472000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 473000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 474000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 475000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 476000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 477000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 478000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 479000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 480000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 480001\n","mean reward (100 episodes) 104.929831\n","best mean reward 125.873252\n","running time 1969.450064\n","Train_EnvstepsSoFar : 480001\n","Train_AverageReturn : 104.92983069700885\n","Train_BestReturn : 125.87325178803174\n","TimeSinceStart : 1969.4500637054443\n","Training Loss : 0.20542998611927032\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 481000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 482000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 483000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 484000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 485000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 486000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 487000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 488000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 489000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 490000 ************\n","\n","Training agent...\n","\n","Beginning logging procedure...\n","Timestep 490001\n","mean reward (100 episodes) 114.645218\n","best mean reward 125.873252\n","running time 2008.266868\n","Train_EnvstepsSoFar : 490001\n","Train_AverageReturn : 114.6452175921788\n","Train_BestReturn : 125.87325178803174\n","TimeSinceStart : 2008.2668681144714\n","Training Loss : 0.15748924016952515\n","Done logging...\n","\n","\n","\n","\n","********** Iteration 491000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 492000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 493000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 494000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 495000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 496000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 497000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 498000 ************\n","\n","Training agent...\n","\n","\n","********** Iteration 499000 ************\n","\n","Training agent...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_kTH-tXkI-B-"},"source":["#@markdown You can visualize your runs with tensorboard from within the notebook\n","\n","## requires tensorflow==2.3.0\n","%load_ext tensorboard\n","%tensorboard --logdir /content/cs285_f2020/homework_fall2020/hw3/data/q1_MsPacman-v0_06-10-2020_18-25-31"],"execution_count":null,"outputs":[]}]}